{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantified Self Project\n",
    "`Period: CPSC 222 01;\n",
    "Prof: Gina Sprint;\n",
    "Name: Ben Puryear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# This is for the plots not being cut off\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the stats?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sleep\n",
    "    * Time in bed(hr)\n",
    "    * The sleep data was collected on my iphone and it tracked everytime after 10pm that I stopped using my phone for more than 15 minutes\n",
    "    * Something to keep in mind is that the sleep time is reset whenever I picked up my phone\n",
    "1. Audio\n",
    "    * Headphone sound levels(dBASPL)\n",
    "    * The audio data was collected on my iphone at random intervals and it would keep track of the current decibel levels (db)\n",
    "1. Movement\n",
    "    * Distance walking / running(mi)\n",
    "        * The amount of miles I traversed in a specific day\n",
    "    * Flights climbed(count)\n",
    "        * The amount of flights of stairs I climbed\n",
    "    * Step count(count)\n",
    "        * The amount of steps I took in a given day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My proccess of Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import the values into either series or dataframes\n",
    "* Convert the values to the right datatype\n",
    "    * The movement data will not be altered\n",
    "    * Any sleep data that is less than half an hour is considered a nap and will not included\n",
    "    *  For audio i will take the average for each day since the data was collected at random intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "1. Why it the domain important to you and why you are researching in this domain\n",
    "    * I am curious about the difference between in school and out of school for my movement, and since I have the option to do sleep and headphone volume I thought it would be interesting to explore them.\n",
    "1. What is the dataset format (e.g. CSV files, JSON files, a mix of the two, etc.)\n",
    "    * all three datasets are in .csv files\n",
    "1. What tables are included in the dataset and how is the data in each table collected\n",
    "    * All data is collected from my iPhone (see `What are the stats?` for each of the attributes)\n",
    "1. Include a brief description of the attributes\n",
    "    * See `What are the stats?`\n",
    "1. What are you trying to classify in the dataset\n",
    "    * I want to clearly show the difference in physical activity during the summer. Adding onto that I want to see if there is a difference between my physical activity/headphone usage/sleep schedule during the weekdays versus the weekend.\n",
    "1. What are potential impacts of the results\n",
    "    * Headphone safety:\n",
    "        * If I notice that I listen to louder music during a specific time of the year, I can look out for that and notice and turn down the volume\n",
    "    * Sleep schedule:\n",
    "        * If I notice that I get way less sleep on the weekdays, it can allow for me to plan my week better and allow for me to get a consistent amount of sleep on both the weekend and weekdays\n",
    "    * Physical activity:\n",
    "        * The main reason for this project would be for me to visually see just how much less activities I did over the summer since my job was a delivery driver\n",
    "1. Who are stakeholders interested in your results\n",
    "    * Me\n",
    "    * Maybe my doctors who would want to monitor my sleep schedule or physical activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Distance walking / running(mi)  Flights climbed(count)  \\\n",
      "Date                                                                 \n",
      "2020-11-21                           1.023                     5.0   \n",
      "2020-11-22                           1.202                     2.0   \n",
      "2020-11-23                           2.455                     8.0   \n",
      "2020-11-24                           1.165                     4.0   \n",
      "2020-11-25                           2.444                     3.0   \n",
      "...                                    ...                     ...   \n",
      "2021-11-17                           2.624                     7.0   \n",
      "2021-11-18                           4.532                     7.0   \n",
      "2021-11-19                           3.492                    10.0   \n",
      "2021-11-20                           0.507                     4.0   \n",
      "2021-11-21                           0.004                     0.0   \n",
      "\n",
      "            Step count(count)  \n",
      "Date                           \n",
      "2020-11-21           2471.000  \n",
      "2020-11-22           2650.515  \n",
      "2020-11-23           5329.485  \n",
      "2020-11-24           2885.000  \n",
      "2020-11-25           5157.000  \n",
      "...                       ...  \n",
      "2021-11-17           6022.000  \n",
      "2021-11-18          10571.000  \n",
      "2021-11-19           8361.000  \n",
      "2021-11-20           1257.000  \n",
      "2021-11-21              9.000  \n",
      "\n",
      "[366 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "movement_data = pd.Series(dtype=float)\n",
    "movement_data = pd.read_csv(\"original_data/puryear_movement.csv\", index_col=0)\n",
    "movement_data.to_csv(\"data/cleaned_puryear_movement.csv\")\n",
    "\n",
    "print(movement_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio\n",
    "\n",
    "format = `%YYYY-%MM-%DD %HH:%MM:%%SS - %YYYY-%MM-%DD %HH:%MM:%%SS,%DB_Val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = pd.DataFrame(dtype=float)\n",
    "audio_data = pd.read_csv(\"original_data/puryear_audio.csv\")\n",
    "\n",
    "# idea for repeating values, find the daily average\n",
    "\n",
    "audio_data_cleaned = pd.Series(dtype=float)\n",
    "\n",
    "for i in range(len(audio_data)):\n",
    "    audio_data_date_string = audio_data.iloc[i][\"Date\"]\n",
    "    cropped_audio_date_string = audio_data_date_string[0:19]\n",
    "    audio_data_cleaned[cropped_audio_date_string] =  audio_data.iloc[i][\"Headphone sound levels(dBASPL)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data_cleaned = audio_data_cleaned.reset_index()\n",
    "audio_data_cleaned.columns=[\"Unnamed: 0\",\"0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the dates of the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data_cleaned_again = pd.Series(dtype=float)\n",
    "\n",
    "# finding the average of the daily values\n",
    "sum = 1\n",
    "amount = audio_data_cleaned.iloc[0][1]\n",
    "audio_data_cleaned_prev_date = audio_data_cleaned.iloc[0][0][0:10]\n",
    "\n",
    "# yes this works!\n",
    "for i in range(1,len(audio_data_cleaned)):\n",
    "    audio_data_cleaned_date = audio_data_cleaned.iloc[i][0][0:10]\n",
    "    if audio_data_cleaned_date == audio_data_cleaned_prev_date: # if this date is the same as the day before do this\n",
    "        sum = sum + 1\n",
    "        amount = amount + audio_data_cleaned.iloc[i][1]\n",
    "    else: # otherwise reset all the values and continue\n",
    "        sum = 1\n",
    "        amount = audio_data_cleaned.iloc[i][1]\n",
    "        audio_data_cleaned_prev_date = audio_data_cleaned.iloc[i][0][0:10]\n",
    "        audio_data_cleaned_again[audio_data_cleaned_date] = (amount / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Headphone sound levels(dBASPL)\n",
      "Date                                      \n",
      "2020-11-22                          66.064\n",
      "2020-11-23                          61.650\n",
      "2020-11-24                          54.927\n",
      "2020-11-25                          57.506\n",
      "2020-11-26                          39.405\n",
      "...                                    ...\n",
      "2021-11-17                          65.809\n",
      "2021-11-18                          62.816\n",
      "2021-11-19                          57.094\n",
      "2021-11-20                          59.618\n",
      "2021-11-21                          60.938\n",
      "\n",
      "[363 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "audio_data_cleaned = pd.DataFrame(audio_data_cleaned_again)\n",
    "audio_data_cleaned.columns = [\"Headphone sound levels(dBASPL)\"]\n",
    "audio_data_cleaned.rename_axis(\"Date\",inplace=True)\n",
    "audio_data_cleaned.to_csv(\"data/cleaned_puryear_audio.csv\")\n",
    "\n",
    "print(audio_data_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that combines the days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_days_in_ser(original_series):\n",
    "    # finding the average of the daily values\n",
    "    sum = 1\n",
    "    amount = original_series.iloc[0][1]\n",
    "    prev_date = original_series.iloc[0][0][0:10]\n",
    "\n",
    "    cleaned_series = pd.Series(dtype=float)\n",
    "\n",
    "    # print(len(original_series))\n",
    "    # yes this works!\n",
    "    for i in range(1,len(original_series)):\n",
    "        original_series_date = original_series.iloc[i][0][0:10]\n",
    "        if original_series_date == prev_date: # if this date is the same as the day before do this\n",
    "            sum = sum + 1\n",
    "            amount = amount + original_series.iloc[i][1]\n",
    "        else: # otherwise reset all the values and continue\n",
    "            sum = 1\n",
    "            amount = original_series.iloc[i][1]\n",
    "            prev_date = original_series.iloc[i][0][0:10]\n",
    "            cleaned_series[original_series_date] = amount\n",
    "\n",
    "    return cleaned_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format = `%YYYY-%MM-%DD %HH:%MM:%%SS - %YYYY-%MM-%DD %HH:%MM:%%SS,%DB_Val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_data = pd.Series(dtype=float)\n",
    "\n",
    "sleep_data = pd.read_csv(\"original_data/puryear_sleep.csv\")\n",
    "\n",
    "# i notice how whenever there is a super small one, its always after a longer one.\n",
    "# my theory is that that is when i actually pick up my phone first, but then i put it down.\n",
    "# maybe i hit snooze\n",
    "\n",
    "# first thing i am going to do is see if i can get the first value before the -, i feel like the stuff after the dash is not needed since we will have the value\n",
    "\n",
    "sleep_data_cleaned = pd.Series(dtype=float)\n",
    "\n",
    "for i in range(len(sleep_data)):\n",
    "    current_date_string = sleep_data.iloc[i][\"Date\"]\n",
    "    cropped_date_string = current_date_string[0:19]\n",
    "    sleep_data_cleaned[cropped_date_string] =  sleep_data.iloc[i][\"Time in bed(hr)\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-22    0.001\n",
      "2020-11-23    6.531\n",
      "2020-11-24    4.332\n",
      "2020-11-25    6.544\n",
      "2020-11-26    8.158\n",
      "              ...  \n",
      "2021-11-17    7.020\n",
      "2021-11-18    4.149\n",
      "2021-11-19    7.006\n",
      "2021-11-20    4.853\n",
      "2021-11-21    6.994\n",
      "Length: 340, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sleep_data_cleaned = sleep_data_cleaned.reset_index()\n",
    "sleep_data_cleaned.columns=[\"Unnamed: 0\",\"0\"]\n",
    "sleep_data_cleaned = combine_days_in_ser(sleep_data_cleaned)\n",
    "print(sleep_data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (1227402450.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/yn/tjtpgl194zq51k3yvb0v6y1c0000gn/T/ipykernel_1655/1227402450.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    ear_sleep.csv\")\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "sleep_data_cleaned = pd.DataFrame(sleep_data_cleaned)\n",
    "sleep_data_cleaned.columns =[\"Time in bed(hr)\"]\n",
    "sleep_data_cleaned.rename_axis(\"Date\",inplace=True)\n",
    "ear_sleep.csv\")\n",
    "\n",
    "print(sleep_data_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "1. What cleaning of the dataset did you need to perform(e.g.. are there missing values and how did you handle the missing values)\n",
    "    * The main thing that I am doing is finding a good way to combine the multiple sleep data points.  \n",
    "        * I could wake up and use my phone from 1 to even 4 times in a single night, be it not being able to sleep or checking the time\n",
    "1. How are you merging the tables\n",
    "    * I am merging the tables based off of their date, and later the day of the week\n",
    "1. What are challenges with data preparation\n",
    "    * The main challenge was with combining multiple sleep data points, since there could be multiple logs for the same \"sleep session\", but those logs could be from different days:\n",
    "        * e.g. sunday at 11:32pm i slept for 33 minutes and the next dataset is monday at 12:05am\n",
    "        * Even though these data points are from different days, they are still back to back and part of the same \"nights sleep\"\n",
    "1. What data aggregation techniques are you applying\n",
    "    * Making sure everything is labeled \n",
    "    * Adding day of the week\n",
    "    * Cleaning up invalid sleep data points (less than half an hour)\n",
    "1. What visualizations informatively present the attributes and relationships\n",
    "    * A line graph is perfect for visualizing the graphs, especially since it is based off of the date\n",
    "1. What statistical hypothesis tests are you computing\n",
    "    * My hypothesis is that there is no difference between the weekend and weekdays for the amount of sleep i get / audio levels / and movement\n",
    "        * This might sound weird but I like to think I keep a consistent sleep schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all 3 dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_data = pd.DataFrame(dtype=float)\n",
    "movement_data = pd.read_csv(\"data/cleaned_puryear_movement.csv\",index_col=0)\n",
    "\n",
    "audio_data = pd.DataFrame(dtype=float)\n",
    "audio_data = pd.read_csv(\"data/cleaned_puryear_audio.csv\",index_col=0)\n",
    "# audio_data.columns = [\"Date\",\"Headphone sound levels(dBASPL)\"]\n",
    "\n",
    "sleep_data = pd.DataFrame(dtype=float)\n",
    "sleep_data = pd.read_csv(\"data/cleaned_puryear_sleep.csv\",index_col=0)\n",
    "# sleep_data.columns = [\"Date\",\"Time in bed(hr)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_and_audio_data = pd.merge(sleep_data,audio_data,on=\"Date\")\n",
    "all_data = pd.merge(sleep_and_audio_data,movement_data, on=\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = movement_data.plot(subplots=True,rot=15)\n",
    "fig = ax[0].get_figure()\n",
    "fig.savefig(\"figures/movement_graph.jpg\",dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = audio_data.plot(subplots=True,rot=15)\n",
    "fig = ax[0].get_figure()\n",
    "fig.savefig(\"figures/audio_graph.jpg\",dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sleep_data.plot(subplots=True,rot=15)\n",
    "fig = ax[0].get_figure()\n",
    "fig.savefig(\"figures/sleep_graph.jpg\",dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = all_data.plot(subplots=True,rot=15)\n",
    "fig = ax[0].get_figure()\n",
    "fig.savefig(\"figures/combined_graph.jpg\",dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Graph\n",
    "<img src=\"https://raw.githubusercontent.com/Ben10164/CPSC222_Project/master/figures/combined_graph.jpg\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate data for VISUAL analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making new dataframes\n",
    "movement_data = pd.DataFrame(dtype=float)\n",
    "movement_data = pd.read_csv(\"data/cleaned_puryear_movement.csv\")\n",
    "\n",
    "audio_data = pd.DataFrame(dtype=float)\n",
    "audio_data = pd.read_csv(\"data/cleaned_puryear_audio.csv\")\n",
    "audio_data.columns = [\"Date\",\"Headphone sound levels(dBASPL)\"]\n",
    "\n",
    "sleep_data = pd.DataFrame(dtype=float)\n",
    "sleep_data = pd.read_csv(\"data/cleaned_puryear_sleep.csv\")\n",
    "sleep_data.columns = [\"Date\",\"Time in bed(hr)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate audio data\n",
    "audio_data.mask((audio_data[\"Headphone sound levels(dBASPL)\"] <= 30) & (audio_data[\"Headphone sound levels(dBASPL)\"] <= 100),inplace=True) # filtering out the outliers\n",
    "audio_data.interpolate(method=\"cubic\",inplace=True)\n",
    "audio_data.fillna(method=\"bfill\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data_combined = audio_data.merge(audio_data[\"Headphone sound levels(dBASPL)\"].ewm(alpha=0.1).mean(),left_index=True,right_index=True)\n",
    "audio_data_combined.columns=[\"Date\",\"Headphone sound levels(dBASPL)\",\"Headphone sound levels(dBASPL) MOVING AVERAGE\"]\n",
    "\n",
    "audio_data_combined.set_index(\"Date\",inplace=True)\n",
    "\n",
    "audio_data_combined.to_csv(\"data/cleaned_puryear_audio_ewm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = audio_data_combined.plot(rot=15)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"figures/moving_avg_audio_graph.jpg\",dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Ben10164/CPSC222_Project/master/figures/moving_avg_audio_graph.jpg\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate sleep data\n",
    "sleep_data.interpolate(method=\"cubic\",inplace=True)\n",
    "sleep_data.fillna(method=\"bfill\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_data_combined = sleep_data.merge(sleep_data[\"Time in bed(hr)\"].ewm(alpha=0.1).mean(),left_index=True,right_index=True)\n",
    "sleep_data_combined.columns=[\"Date\",\"Time in bed(hr)\",\"Time in bed(hr) MOVING AVERAGE\"]\n",
    "\n",
    "sleep_data_combined.set_index(\"Date\",inplace=True)\n",
    "\n",
    "sleep_data_combined.to_csv(\"data/cleaned_puryear_sleep_ewm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sleep_data_combined.plot(rot=15)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"figures/moving_avg_sleep_graph.jpg\",dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/Ben10164/CPSC222_Project/master/figures/moving_avg_sleep_graph.jpg\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate movement data\n",
    "movement_data.interpolate(method=\"cubic\",inplace=True)\n",
    "movement_data.fillna(method=\"bfill\",inplace=True)\n",
    "\n",
    "movement_data_distance = pd.DataFrame(movement_data[\"Distance walking / running(mi)\"])\n",
    "movement_data_flights = pd.DataFrame(movement_data[\"Flights climbed(count)\"])\n",
    "movement_data_step = pd.DataFrame(movement_data[\"Step count(count)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset indexes\n",
    "movement_data_distance.set_index(movement_data[\"Date\"],inplace=True)\n",
    "movement_data_flights.set_index(movement_data[\"Date\"],inplace=True)\n",
    "movement_data_step.set_index(movement_data[\"Date\"],inplace=True)\n",
    "\n",
    "# create the combined datasets\n",
    "movement_data_distance_combined = movement_data_distance.merge(movement_data_distance[\"Distance walking / running(mi)\"].ewm(alpha=0.1).mean(),left_index=True,right_index=True)\n",
    "movement_data_flights_combined = movement_data_flights.merge(movement_data_flights[\"Flights climbed(count)\"].ewm(alpha=0.1).mean(),left_index=True,right_index=True)\n",
    "movement_data_step_combined = movement_data_step.merge(movement_data_step[\"Step count(count)\"].ewm(alpha=0.1).mean(),left_index=True,right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "movement_data_distance_combined.columns=[\"Distance walking / running(mi)\",\"Distance walking / running(mi) MOVING AVERAGE\"]\n",
    "movement_data_flights_combined.columns=[\"Flights climbed(count)\",\"Flights climbed(count) MOVING AVERAGE\"]\n",
    "movement_data_step_combined.columns=[\"Step count(count)\",\"Step count(count) MOVING AVERAGE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to csv\n",
    "movement_data_distance_combined.to_csv(\"data/clean_puryear_movement_distance_ewm.csv\")\n",
    "movement_data_flights_combined.to_csv(\"data/clean_puryear_movement_flights_ewm.csv\")\n",
    "movement_data_step_combined.to_csv(\"data/clean_puryear_movement_step_ewm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and output plots\n",
    "ax = movement_data_distance_combined.plot(rot=15)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"figures/moving_avg_movement_distance_graph.jpg\",dpi=500)\n",
    "\n",
    "ax = movement_data_flights_combined.plot(rot=15)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"figures/moving_avg_movement_flights_graph.jpg\",dpi=500)\n",
    "\n",
    "ax = movement_data_step_combined.plot(rot=15)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"figures/moving_avg_movement_steps_graph.jpg\",dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first thing that sticks out is how obvious it is when I am at school vs home.\n",
    "    * The step count decreases a lot during the summer\n",
    "    * The distance walking / running decreases during the summer\n",
    "* On the 17th of August there is a large spike for flights climbed\n",
    "    * This was when a friend was visiting and we went hiking\n",
    "* There is a very clear dip in my sleep during late July and early August\n",
    "* Early June there is an extremely large spike in db for the headphone sound levels\n",
    "    * This is most likely because it was around that time that I started my job as a delivery driver\n",
    "* There is a clear difference between the first half of Spring 2020 and the second half for distance walking / running\n",
    "    * This is most likely because early March I started dating someone who lived across the campus\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis / Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The subject has exported his iPhones movement data, as well as his sleep and headphone volume data. Using a level of significance of 0.1, is there any major difference between the data for the weekdays vs the weekends?\n",
    "* Null Hypothesis:\n",
    "    * There is no significant difference: $\\alpha \\le 0.1$\n",
    "* Alternate Hypothesis:\n",
    "    * There is a significant difference: $\\alpha \\gt 0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the date of the week of a given date in the format of 'YYYY-MM-DD'\n",
    "def get_weekday(date):\n",
    "    return pd.to_datetime(date).strftime('%A')\n",
    "\n",
    "audio_df = pd.read_csv(\"data/cleaned_puryear_audio.csv\",index_col=0)\n",
    "movement_df = pd.read_csv(\"data/cleaned_puryear_movement.csv\",index_col=0)\n",
    "sleep_df = pd.read_csv(\"data/cleaned_puryear_sleep.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dataframe_of_weekend(df):\n",
    "    df = df.reset_index()\n",
    "    weekday_df = pd.DataFrame()\n",
    "    weekday_df['Weekday'] = df['Date'].apply(get_weekday)\n",
    "    df = df.join(weekday_df)\n",
    "    sunday_and_saturday_df = df[df['Weekday'] == 'Sunday'].append(df[df['Weekday'] == 'Saturday']) # append the dataframe of all weekends\n",
    "    sunday_and_saturday_df['Date'] = pd.to_datetime(sunday_and_saturday_df['Date']) # convert to datetime\n",
    "    sunday_and_saturday_df['Date'] = sunday_and_saturday_df['Date'].dt.strftime('%Y-%m-%d') # set the format of the date to 'YYYY-MM-DD'\n",
    "    sunday_and_saturday_df = sunday_and_saturday_df.sort_values(by=['Date']) # sort by date\n",
    "    sunday_and_saturday_df.set_index(\"Date\",inplace=True)\n",
    "    return sunday_and_saturday_df\n",
    "\n",
    "weekend_audio_df = return_dataframe_of_weekend(audio_df)\n",
    "weekend_movement_df = return_dataframe_of_weekend(movement_df)\n",
    "weekend_sleep_df = return_dataframe_of_weekend(sleep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dataframe_of_weekday(df):\n",
    "    df = df.reset_index()\n",
    "    weekday_df = pd.DataFrame()\n",
    "    weekday_df['Weekday'] = df['Date'].apply(get_weekday)\n",
    "    df = df.join(weekday_df)\n",
    "\n",
    "    weekdays_df = df[df['Weekday'] != 'Sunday']\n",
    "    weekdays_df = weekdays_df[weekdays_df['Weekday'] != 'Saturday']\n",
    "    weekdays_df['Date'] = pd.to_datetime(weekdays_df['Date']) # convert to datetime\n",
    "    weekdays_df['Date'] = weekdays_df['Date'].dt.strftime('%Y-%m-%d') # set the format of the date to 'YYYY-MM-DD'\n",
    "    weekdays_df = weekdays_df.sort_values(by=['Date']) # sort by date\n",
    "    weekdays_df.set_index(\"Date\",inplace=True)\n",
    "\n",
    "    return weekdays_df\n",
    "\n",
    "weekday_audio_df = return_dataframe_of_weekday(audio_df)\n",
    "weekday_movement_df = return_dataframe_of_weekday(movement_df)\n",
    "weekday_sleep_df = return_dataframe_of_weekday(sleep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p = stats.ttest_ind(weekday_sleep_df[\"Time in bed(hr)\"],weekend_sleep_df[\"Time in bed(hr)\"])\n",
    "\n",
    "print(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is a difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p = stats.ttest_ind(weekday_audio_df[\"Headphone sound levels(dBASPL)\"],weekend_audio_df[\"Headphone sound levels(dBASPL)\"])\n",
    "\n",
    "print(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is not a difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p = stats.ttest_ind(weekday_movement_df[\"Step count(count)\"],weekend_movement_df[\"Step count(count)\"])\n",
    "\n",
    "print(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is no difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p = stats.ttest_ind(weekday_movement_df[\"Distance walking / running(mi)\"],weekend_movement_df[\"Distance walking / running(mi)\"])\n",
    "\n",
    "print(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is a difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flights climbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p = stats.ttest_ind(weekday_movement_df[\"Flights climbed(count)\"],weekend_movement_df[\"Flights climbed(count)\"])\n",
    "\n",
    "print(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is no difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data | P-Val | Significant Difference | Insignificant Difference |\n",
    "|--|--|--|--|\n",
    "| Audio | 0.59 | | x |\n",
    "| Sleep | 0.08 | x | |\n",
    "| Steps | 0.11 | | x |\n",
    "| Distance | 0.08 | x | |\n",
    "| Flights | 0.41 | | x |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the table shown above, only the sleep and distance data had a significant difference on the weekend vs the weekday.  \n",
    "This means that only sleep and distance had a p value that was less than our alpha ($\\alpha=0.1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1. What attribute are you using as class information (i.e., what attribute or attributes are you predicting)\n",
    "    * The attribute that I am predicting is if it is a weekday or a weekend\n",
    "1. What are your hypotheses about the predictions\n",
    "    * My hypothesis is that the kNN classifier will be able to be above 0.71 (5/7)\n",
    "    * I also think that the accuracy for sleep will be the highest out of all other datasets\n",
    "        * Accuracy > 0.8\n",
    "1. In addition to kNN, what other classifiers are you using and comparing results with\n",
    "    * I compared it to the tree classifier. The results were lackluster when comparing it to the optimized amount of folds, but with calculating the optimal folds for kNN being inefficient, the tree classifier might be more efficient \n",
    "1. How are you evaluating performance\n",
    "    * In order for me to judge how well an algorithm is doing I would use it against the test set and find the accuracy\n",
    "1. What are challenges with classification\n",
    "    * I feel like a reason the data wasn't terribly accurate was because the amount of data points is so small. As much as that sounds like an excuse that a bad data scientists would make, I believe that the little amount of data I have means that outliers and incomplete data points have a much larger impact even after minmaxscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction with Scikit-Learn\n",
    "Steps:\n",
    "1. Load data\n",
    "1. Normalize\n",
    "1. Train kNN classifier with training set\n",
    "1. Test kNN classifier on test instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, predicting_attribute, test_data ):\n",
    "    X_train = df.drop(predicting_attribute,axis=1)\n",
    "    y_train = df[predicting_attribute]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_normalized = scaler.transform(X_train) # often combined into one step, using fit_transform()\n",
    "\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "    neigh.fit(X_train_normalized, y_train)\n",
    "\n",
    "    X_test = pd.Series(test_data, index=df.columns.drop(predicting_attribute))\n",
    "    X_test = scaler.transform([X_test])\n",
    "    y_test_prediction = neigh.predict(X_test)\n",
    "\n",
    "    return(y_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the date of the week of a given date in the format of 'YYYY-MM-DD'\n",
    "def get_weekday(date):\n",
    "    return pd.to_datetime(date).strftime('%A')\n",
    "\n",
    "audio_df = pd.read_csv(\"data/cleaned_puryear_audio.csv\",index_col=0)\n",
    "movement_df = pd.read_csv(\"data/cleaned_puryear_movement.csv\",index_col=0)\n",
    "sleep_df = pd.read_csv(\"data/cleaned_puryear_sleep.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dataframe_with_weekday(df):\n",
    "    df = df.reset_index()\n",
    "    weekday_df = pd.DataFrame()\n",
    "    weekday_df['Weekday'] = df['Date'].apply(get_weekday)\n",
    "    df = df.join(weekday_df)\n",
    "    df.set_index(\"Date\",inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "weekday_audio_df = return_dataframe_with_weekday(audio_df)\n",
    "weekday_movement_df = return_dataframe_with_weekday(movement_df)\n",
    "weekday_sleep_df = return_dataframe_with_weekday(sleep_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of kNN\n",
    "* My goal for the main kNN function is to predict the day of the week when given all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_and_audio_data = pd.merge(sleep_df,audio_df,on=\"Date\")\n",
    "all_data = pd.merge(sleep_and_audio_data,weekday_movement_df, on=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekend_yes_no_df(df):\n",
    "    df.replace(\"Monday\",\"Weekday\",inplace=True)\n",
    "    df.replace(\"Tuesday\",\"Weekday\",inplace=True)\n",
    "    df.replace(\"Wednesday\",\"Weekday\",inplace=True)\n",
    "    df.replace(\"Thursday\",\"Weekday\",inplace=True)\n",
    "    df.replace(\"Friday\",\"Weekday\",inplace=True)\n",
    "    df.replace(\"Saturday\",\"Weekend\",inplace=True)\n",
    "    df.replace(\"Sunday\",\"Weekend\",inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = get_weekend_yes_no_df(all_data)\n",
    "print(all_data[\"Weekday\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data.drop(columns=\"Weekday\",axis=1)\n",
    "y = all_data[\"Weekday\"]\n",
    "\n",
    "scaler= MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block will calculate the kNN classifier for each n_neighbors between 1 and 224 and see which is the best\n",
    "best_n = 0\n",
    "best_n_val = 0\n",
    "for i in range(1,224):\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=i, metric=\"euclidean\")\n",
    "    knn_clf.fit(X_train,y_train)\n",
    "    y_predicted = knn_clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "\n",
    "    if accuracy > best_n_val:\n",
    "        best_n = i\n",
    "        best_n_val = accuracy\n",
    "\n",
    "print(\"The best accuracy was\", best_n_val,\"with an n-val of\",best_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets make it a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kNN_prediction_accuracy(df,column):\n",
    "    X = df.drop(columns=column,axis=1)\n",
    "    y = df[column]\n",
    "\n",
    "    scaler= MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0,stratify=y)\n",
    "\n",
    "    # This block will calculate the kNN classifier for each n_neighbors between 1 and 224 and see which is the best\n",
    "    best_n = 0\n",
    "    best_n_val = 0\n",
    "    for i in range(1,224):\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors=i, metric=\"euclidean\")\n",
    "        knn_clf.fit(X_train,y_train)\n",
    "        y_predicted = knn_clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_predicted)\n",
    "\n",
    "        if accuracy > best_n_val:\n",
    "            best_n = i\n",
    "            best_n_val = accuracy\n",
    "\n",
    "    # Again but with a decision tree\n",
    "    tree_clf = DecisionTreeClassifier(random_state=0)\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    y_predicted = tree_clf.predict(X_test)\n",
    "    tree_accuracy = accuracy_score(y_test, y_predicted)\n",
    "\n",
    "    return best_n_val, best_n,tree_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_accuracy, audio_n,audio_tree_acc = get_kNN_prediction_accuracy(get_weekend_yes_no_df(weekday_audio_df),\"Weekday\")\n",
    "print(\"The accuracy of the kNN for audio was\",audio_accuracy,\"when the n_neighbors was\",audio_n,\" but with the use of a tree the accuracy was\",audio_tree_acc)\n",
    "\n",
    "sleep_accuracy, sleep_n,sleep_tree_acc = get_kNN_prediction_accuracy(get_weekend_yes_no_df(weekday_sleep_df),\"Weekday\")\n",
    "print(\"The accuracy of the kNN for sleep was\",sleep_accuracy,\"when the n_neighbors was\",sleep_n,\"but with the use of a tree the accuracy was\",sleep_tree_acc)\n",
    "\n",
    "movement_accuracy, movement_n,movement_tree_acc = get_kNN_prediction_accuracy(get_weekend_yes_no_df(weekday_movement_df),\"Weekday\")\n",
    "print(\"The accuracy of the kNN for movement was\",movement_accuracy,\"when the n_neighbors was\",movement_n,\"but with the use of a tree the accuracy was\",movement_tree_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of kNN\n",
    "* Based on the results we can see that there is a slight corelation between the data and if it is the weekend or not!\n",
    "    * There is an accuracy of 0.74 on predicting if the data is on a weekday or weekend\n",
    "* We can also see that sleep/movement and the day of the week are slightly correlated as well\n",
    "* Out of the three attributes, all 3 were relatively similar on their connection to the date, with their prediction accuracy being relatively close\n",
    "* The accuracy is still a bit of a letdown. I hoped that the accuracy would be in the mid 80s for sleep\n",
    "* The tree clf was inferior to the kNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "### A short summary of the dataset you used (and any of its inherent challenges for classification)\n",
    "* The datsets that I used were all from my phone from the apple health app. I used the built in export for the movement data as well as a third party app used to export the audio and sleep data since there is no default way to export them yet. The movement dataset includes the daily amount of flights I climbed, daily steps I took, as well as the total miles walked or ran throughout the day. The audio data contains the current decibel level at a random point during the day. After some reason I still can not find what causes an instance to be recorded. The sleep data is a collection of times past 10pm and before 9:00am that I do not use my phone for more than 15 minutes. Out of all of the datasets, the sleep dataset was the most difficult for me to clean up. This was because there could be a datapoint that disrupts the night because I wake up to check the time. My solution was to add up all the times in a single night, and if the time of the data is after midnight, I add it to the previous days statistic.\n",
    "    \n",
    "### The classification approach you developed, your classifiers’ performance, and any ideas you have on ways to improve performance. \n",
    "* There were two different forms of classification that I developed, tree and kNN, with kNN being the main focus of the classification section. Out of the two, kNN outperformed tree classifiers, but that could also have been because of my kNN n_folds optimization. I would iteratively make a new kNN classifier and test it, increasing the amount of folds from 1 to the datalimit, keeping track on the best performing amount of folds. Like I said in the classifier analysis section, this is not very efficient. Comparing that to the tree classifier that I only needed to use once and get a similar result (5-10% lower accuracy) especially considering the amount of computing used. Both of the classifiers would take the data in as the input and return their predicted day of the week (specifically if it was on the weekend or not). \n",
    "\n",
    "### Describe the potential impacts of your work (including ethical impacts) for the stakeholder’s you described in the introduction.\n",
    "* The two stakeholder's that I described in the introduction were me and my doctors if they ever wanted to make patterns or view my physical/auditorial/sleep history. Since the main stakeholder in this data is me, the person who is conducting, I do not see any ethical impacts that could result from this work. When it comes to other potential impacts, if I continued putting in my date it would be very easy for me to monitor my physical activity, as well as prepare for trends. An example could be that I notice that I start to list to louder music during a specific month, I could make sure to go out of my way to listen to quieter music during that year in order for me to protect my ears and prevent ear damage.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42f2e04143d7207fe24b7231a7967b30a58f6a4af2031ceb790690a1f6850973"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
